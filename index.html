<!DOCTYPE html>
<html>
<head>
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-168011222-1"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'UA-168011222-1');
	</script>
	<!-- Google fonts -->
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700">
	<!-- Site info -->
	<title>Tyler A. Chang</title>
	<meta name="author" content="Tyler A. Chang">
	<meta name="description" content="Tyler Chang, PhD student at UC San Diego.">
	<meta name="keywords" content="Tyler Chang, Carleton, UC San Diego, UCSD">
	<meta name="google-site-verification" content="rCmbByGQ7v60goauxCsOqJSLGF2JA8BB2EkoA2E05r8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<!--Open Graph tags -->
	<meta property="og:title" content="Tyler A. Chang" />
	<meta property="og:type" content="website" />
	<meta property="og:url" content="https://tylerachang.github.io/" />
	<meta property="og:image" content="hawaii.jpg" />
	<meta property="og:image:width" content="3264" />
	<meta property="og:image:height" content="2448" />
	<meta property="og:description" content="Tyler Chang, PhD student at UC San Diego." />
	<!-- Links -->
	<link rel="canonical" href="https://tylerachang.github.io/">
    <link rel="shortcut icon" href="icon.ico">
    <link rel="stylesheet" type="text/css" href="style.css">
</head>
<body>
    <div id="sidebar"></div>
	<div id="topbar">
	</div>
	<div id="main-box">
		<div class="content">
			<div class="header">Tyler Chang</div>
            <div class="subheader">PhD Student at UC San Diego.</div>
            <!-- &nbsp<a class="paragraph" style="display:inline;font-weight:bold;" target="_blank" href="tyler_chang_cv.pdf">[Link to CV]</a> -->
			<div class="paragraph" style="font-weight:bold;">Natural Language Processing / Cognitive Linguistics / Computational Linguistics.</div><br>
			<div class="paragraph">Hello!
			I am a cognitive science PhD student at UCSD and a student researcher at Google's Responsible AI team.
            I am also affiliated with the Halıcıoğlu Data Science Institute at UCSD.
			I am interested in how people, machines, and artificial agents learn, comprehend, and produce language.
			My recent work has focused on the analysis of large language models, particularly during pre-training.
			</div><br>
			<img id="selfimage" src="hawaii.jpg" alt="Hawaii"><br>
			<div class="paragraph">
			I completed my undergrad at Carleton College in Northfield, Minnesota, majoring in math and cognitive science.
			During undergrad, I studied linguistics and mathematics in Japan and Hungary.
			In the past, I have worked on artificial intelligence teams at Amazon and Google.
            My CV is <a target="_blank" href="tyler_chang_cv.pdf">[here]</a>.<br><br>
			Feel free to contact me at <span>tachang@ucsd.edu</span>!
			</div><br>   
            
			<div class="subheader" style="display:inline;">Research</div>&nbsp&nbsp
			<a class="paragraph" style="display:inline;" target="_blank" href="https://scholar.google.com/citations?user=zkDuqfwAAAAJ">[Google Scholar]</a>&nbsp
			<a class="paragraph" style="display:inline;" target="_blank" href="https://www.semanticscholar.org/author/Tyler-A.-Chang/2087001989">[Semantic Scholar]</a>&nbsp
			<a class="paragraph" style="display:inline;" target="_blank" href="https://github.com/tylerachang">[Github]</a>&nbsp
			<!-- <a class="paragraph" style="display:inline;" target="_blank" href="tyler_chang_cv.pdf">[CV]</a> -->
			<br>

			<div class="publication">Chang, T. A., & Bergen, B. K. (under review). Language model behavior: A comprehensive survey.&nbsp <a target="_blank" href="https://arxiv.org/abs/2303.11504">[Preprint]</a></div>

			<div class="publication">Trott, S., Jones, C. R., Chang, T. A., Michaelov, J., & Bergen, B. K. (under review). Do large language models know what humans know?&nbsp <a target="_blank" href="https://arxiv.org/abs/2209.01515">[Preprint]</a></div>
			<hr>

			<div class="publication">Chang, T. A., Halder, K., Anna John, N., Vyas, Y., Benajiba, Y., Ballesteros, M., & Roth, D. (2023). Characterizing and measuring linguistic dataset drift. <i>Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</i> (ACL). To appear.</div>

			<div class="publication">Chang, T. A., Tu, Z., & Bergen, B. K. (2022). The geometry of multilingual language model representations. <i>Proceedings of the Conference on Empirical Methods in Natural Language Processing</i> (EMNLP).&nbsp <a target="_blank" href="https://aclanthology.org/2022.emnlp-main.9/">[Paper]</a>&nbsp <a target="_blank" href="https://github.com/tylerachang/multilingual-geometry">[Code]</a></div>

			<div class="publication">Chang, T. A., & Bergen, B. K. (2022). Word acquisition in neural language models. <i>Transactions of the Association for Computational Linguistics</i> (TACL). Presented at ACL 2022.&nbsp <a target="_blank" href="https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00444/109271/Word-Acquisition-in-Neural-Language-Models">[Paper]</a>&nbsp <a target="_blank" href="https://github.com/tylerachang/word-acquisition-language-models">[Code]</a></div>

			<div class="publication">Chang, T. A., & Bergen, B. K. (2022). Does contextual diversity hinder early word acquisition? <i>Proceedings of the 44th Annual Conference of the Cognitive Science Society</i> (CogSci).&nbsp <a target="_blank" href="https://escholarship.org/uc/item/6r4132wr">[Paper]</a>&nbsp <a target="_blank" href="https://github.com/tylerachang/contextual-diversity">[Code]</a></div>

			<div class="publication">Jones, C. R., Chang, T. A., Coulson, S., Michaelov, J. A., Trott, S., & Bergen, B. K. (2022). Distributional semantics still can’t account for affordances. <i>Proceedings of the 44th Annual Conference of the Cognitive Science Society</i> (CogSci).&nbsp <a target="_blank" href="https://escholarship.org/uc/item/44z7r3j3">[Paper]</a></div>

			<div class="publication">Chang, T. A., Xu, Y., Xu, W., & Tu, Z. (2021). Convolutions and self-attention: Re-interpreting relative positions in pre-trained language models. <i>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</i> (ACL-IJCNLP).&nbsp <a target="_blank" href="https://aclanthology.org/2021.acl-long.333/">[Paper]</a>&nbsp <a target="_blank" href="https://github.com/mlpc-ucsd/BERT_Convolutions">[Code]</a></div>

			<div class="publication">Xu, W., Xu, Y., Chang, T. A., & Tu, Z. (2021). Co-scale conv-attentional image transformers. <i>Proceedings of the IEEE/CVF International Conference on Computer Vision</i> (ICCV).&nbsp <a target="_blank" href="https://arxiv.org/abs/2104.06399">[Paper]</a>&nbsp <a target="_blank" href="https://github.com/mlpc-ucsd/CoaT">[Code]</a></div>

			<div class="publication">Chang, T. A., & Rafferty, A. N. (2020). Encodings of source syntax: Similarities in NMT representations across target languages. <i>Proceedings of the 5th Workshop on Representation Learning for NLP</i> (workshop at ACL).&nbsp <a target="_blank" href="https://www.aclweb.org/anthology/2020.repl4nlp-1.2/">[Link]</a></div>
			<hr>

			<div class="publication">Chang, T. A. (2020). Emergence of hierarchical syntax in neural machine translation. <i>Carleton Digital Commons, Undergraduate Thesis.</i> Carleton College, Cognitive Science Department. With distinction.&nbsp <a target="_blank" href="https://digitalcommons.carleton.edu/comps/2724/">[Link]</a>&nbsp <a target="_blank" href="paper_pdfs/Tyler_Chang-cog_sci_comps-online.pdf">[PDF]</a></div>

			<div class="publication">Chang, T. A. (2020). Topology of second order tensor fields. <i>Carleton Digital Commons, Undergraduate Thesis.</i> Carleton College, Mathematics Department.&nbsp <a target="_blank" href="https://digitalcommons.carleton.edu/comps/2747/">[Link]</a>&nbsp <a target="_blank" href="paper_pdfs/Tyler_Chang-math_comps-online.pdf">[PDF]</a></div>
			<br><br>
		</div>
	</div>
</body>
</html>